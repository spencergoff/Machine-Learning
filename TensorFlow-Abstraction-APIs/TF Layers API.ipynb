{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Data Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- 1) Alcohol\n",
      " \t\t- 2) Malic acid\n",
      " \t\t- 3) Ash\n",
      "\t\t- 4) Alcalinity of ash  \n",
      " \t\t- 5) Magnesium\n",
      "\t\t- 6) Total phenols\n",
      " \t\t- 7) Flavanoids\n",
      " \t\t- 8) Nonflavanoid phenols\n",
      " \t\t- 9) Proanthocyanins\n",
      "\t\t- 10)Color intensity\n",
      " \t\t- 11)Hue\n",
      " \t\t- 12)OD280/OD315 of diluted wines\n",
      " \t\t- 13)Proline\n",
      "        \t- class:\n",
      "                - class_0\n",
      "                - class_1\n",
      "                - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      "References\n",
      "----------\n",
      "(1) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "Comparison of Classifiers in High Dimensional Settings, \n",
      "Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Technometrics). \n",
      "\n",
      "The data was used with many others for comparing various \n",
      "classifiers. The classes are separable, though only RDA \n",
      "has achieved 100% correct classification. \n",
      "(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "(All results using the leave-one-out technique) \n",
      "\n",
      "(2) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "\"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Journal of Chemometrics). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine_data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_data = wine_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.42300000e+01,   1.71000000e+00,   2.43000000e+00, ...,\n",
       "          1.04000000e+00,   3.92000000e+00,   1.06500000e+03],\n",
       "       [  1.32000000e+01,   1.78000000e+00,   2.14000000e+00, ...,\n",
       "          1.05000000e+00,   3.40000000e+00,   1.05000000e+03],\n",
       "       [  1.31600000e+01,   2.36000000e+00,   2.67000000e+00, ...,\n",
       "          1.03000000e+00,   3.17000000e+00,   1.18500000e+03],\n",
       "       ..., \n",
       "       [  1.32700000e+01,   4.28000000e+00,   2.26000000e+00, ...,\n",
       "          5.90000000e-01,   1.56000000e+00,   8.35000000e+02],\n",
       "       [  1.31700000e+01,   2.59000000e+00,   2.37000000e+00, ...,\n",
       "          6.00000000e-01,   1.62000000e+00,   8.40000000e+02],\n",
       "       [  1.41300000e+01,   4.10000000e+00,   2.74000000e+00, ...,\n",
       "          6.10000000e-01,   1.60000000e+00,   5.60000000e+02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = wine_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  1.34800000e+01,   1.67000000e+00,   2.64000000e+00, ...,\n",
       "           5.70000000e-01,   1.78000000e+00,   6.20000000e+02],\n",
       "        [  1.18400000e+01,   8.90000000e-01,   2.58000000e+00, ...,\n",
       "           7.90000000e-01,   3.08000000e+00,   5.20000000e+02],\n",
       "        [  1.32400000e+01,   2.59000000e+00,   2.87000000e+00, ...,\n",
       "           1.04000000e+00,   2.93000000e+00,   7.35000000e+02],\n",
       "        ..., \n",
       "        [  1.43800000e+01,   1.87000000e+00,   2.38000000e+00, ...,\n",
       "           1.20000000e+00,   3.00000000e+00,   1.54700000e+03],\n",
       "        [  1.23300000e+01,   1.10000000e+00,   2.28000000e+00, ...,\n",
       "           1.25000000e+00,   1.67000000e+00,   6.80000000e+02],\n",
       "        [  1.26400000e+01,   1.36000000e+00,   2.02000000e+00, ...,\n",
       "           9.80000000e-01,   1.59000000e+00,   4.50000000e+02]]),\n",
       " array([[  1.29300000e+01,   2.81000000e+00,   2.70000000e+00,\n",
       "           2.10000000e+01,   9.60000000e+01,   1.54000000e+00,\n",
       "           5.00000000e-01,   5.30000000e-01,   7.50000000e-01,\n",
       "           4.60000000e+00,   7.70000000e-01,   2.31000000e+00,\n",
       "           6.00000000e+02],\n",
       "        [  1.40600000e+01,   2.15000000e+00,   2.61000000e+00,\n",
       "           1.76000000e+01,   1.21000000e+02,   2.60000000e+00,\n",
       "           2.51000000e+00,   3.10000000e-01,   1.25000000e+00,\n",
       "           5.05000000e+00,   1.06000000e+00,   3.58000000e+00,\n",
       "           1.29500000e+03],\n",
       "        [  1.14600000e+01,   3.74000000e+00,   1.82000000e+00,\n",
       "           1.95000000e+01,   1.07000000e+02,   3.18000000e+00,\n",
       "           2.58000000e+00,   2.40000000e-01,   3.58000000e+00,\n",
       "           2.90000000e+00,   7.50000000e-01,   2.81000000e+00,\n",
       "           5.62000000e+02],\n",
       "        [  1.30300000e+01,   9.00000000e-01,   1.71000000e+00,\n",
       "           1.60000000e+01,   8.60000000e+01,   1.95000000e+00,\n",
       "           2.03000000e+00,   2.40000000e-01,   1.46000000e+00,\n",
       "           4.60000000e+00,   1.19000000e+00,   2.48000000e+00,\n",
       "           3.92000000e+02],\n",
       "        [  1.34500000e+01,   3.70000000e+00,   2.60000000e+00,\n",
       "           2.30000000e+01,   1.11000000e+02,   1.70000000e+00,\n",
       "           9.20000000e-01,   4.30000000e-01,   1.46000000e+00,\n",
       "           1.06800000e+01,   8.50000000e-01,   1.56000000e+00,\n",
       "           6.95000000e+02],\n",
       "        [  1.22900000e+01,   1.61000000e+00,   2.21000000e+00,\n",
       "           2.04000000e+01,   1.03000000e+02,   1.10000000e+00,\n",
       "           1.02000000e+00,   3.70000000e-01,   1.46000000e+00,\n",
       "           3.05000000e+00,   9.06000000e-01,   1.82000000e+00,\n",
       "           8.70000000e+02],\n",
       "        [  1.36400000e+01,   3.10000000e+00,   2.56000000e+00,\n",
       "           1.52000000e+01,   1.16000000e+02,   2.70000000e+00,\n",
       "           3.03000000e+00,   1.70000000e-01,   1.66000000e+00,\n",
       "           5.10000000e+00,   9.60000000e-01,   3.36000000e+00,\n",
       "           8.45000000e+02],\n",
       "        [  1.35800000e+01,   1.66000000e+00,   2.36000000e+00,\n",
       "           1.91000000e+01,   1.06000000e+02,   2.86000000e+00,\n",
       "           3.19000000e+00,   2.20000000e-01,   1.95000000e+00,\n",
       "           6.90000000e+00,   1.09000000e+00,   2.88000000e+00,\n",
       "           1.51500000e+03],\n",
       "        [  1.26700000e+01,   9.80000000e-01,   2.24000000e+00,\n",
       "           1.80000000e+01,   9.90000000e+01,   2.20000000e+00,\n",
       "           1.94000000e+00,   3.00000000e-01,   1.46000000e+00,\n",
       "           2.62000000e+00,   1.23000000e+00,   3.16000000e+00,\n",
       "           4.50000000e+02],\n",
       "        [  1.10300000e+01,   1.51000000e+00,   2.20000000e+00,\n",
       "           2.15000000e+01,   8.50000000e+01,   2.46000000e+00,\n",
       "           2.17000000e+00,   5.20000000e-01,   2.01000000e+00,\n",
       "           1.90000000e+00,   1.71000000e+00,   2.87000000e+00,\n",
       "           4.07000000e+02],\n",
       "        [  1.37100000e+01,   1.86000000e+00,   2.36000000e+00,\n",
       "           1.66000000e+01,   1.01000000e+02,   2.61000000e+00,\n",
       "           2.88000000e+00,   2.70000000e-01,   1.69000000e+00,\n",
       "           3.80000000e+00,   1.11000000e+00,   4.00000000e+00,\n",
       "           1.03500000e+03],\n",
       "        [  1.24200000e+01,   4.43000000e+00,   2.73000000e+00,\n",
       "           2.65000000e+01,   1.02000000e+02,   2.20000000e+00,\n",
       "           2.13000000e+00,   4.30000000e-01,   1.71000000e+00,\n",
       "           2.08000000e+00,   9.20000000e-01,   3.12000000e+00,\n",
       "           3.65000000e+02],\n",
       "        [  1.41300000e+01,   4.10000000e+00,   2.74000000e+00,\n",
       "           2.45000000e+01,   9.60000000e+01,   2.05000000e+00,\n",
       "           7.60000000e-01,   5.60000000e-01,   1.35000000e+00,\n",
       "           9.20000000e+00,   6.10000000e-01,   1.60000000e+00,\n",
       "           5.60000000e+02],\n",
       "        [  1.34800000e+01,   1.81000000e+00,   2.41000000e+00,\n",
       "           2.05000000e+01,   1.00000000e+02,   2.70000000e+00,\n",
       "           2.98000000e+00,   2.60000000e-01,   1.86000000e+00,\n",
       "           5.10000000e+00,   1.04000000e+00,   3.47000000e+00,\n",
       "           9.20000000e+02],\n",
       "        [  1.22100000e+01,   1.19000000e+00,   1.75000000e+00,\n",
       "           1.68000000e+01,   1.51000000e+02,   1.85000000e+00,\n",
       "           1.28000000e+00,   1.40000000e-01,   2.50000000e+00,\n",
       "           2.85000000e+00,   1.28000000e+00,   3.07000000e+00,\n",
       "           7.18000000e+02],\n",
       "        [  1.23300000e+01,   9.90000000e-01,   1.95000000e+00,\n",
       "           1.48000000e+01,   1.36000000e+02,   1.90000000e+00,\n",
       "           1.85000000e+00,   3.50000000e-01,   2.76000000e+00,\n",
       "           3.40000000e+00,   1.06000000e+00,   2.31000000e+00,\n",
       "           7.50000000e+02],\n",
       "        [  1.34100000e+01,   3.84000000e+00,   2.12000000e+00,\n",
       "           1.88000000e+01,   9.00000000e+01,   2.45000000e+00,\n",
       "           2.68000000e+00,   2.70000000e-01,   1.48000000e+00,\n",
       "           4.28000000e+00,   9.10000000e-01,   3.00000000e+00,\n",
       "           1.03500000e+03],\n",
       "        [  1.42000000e+01,   1.76000000e+00,   2.45000000e+00,\n",
       "           1.52000000e+01,   1.12000000e+02,   3.27000000e+00,\n",
       "           3.39000000e+00,   3.40000000e-01,   1.97000000e+00,\n",
       "           6.75000000e+00,   1.05000000e+00,   2.85000000e+00,\n",
       "           1.45000000e+03],\n",
       "        [  1.17900000e+01,   2.13000000e+00,   2.78000000e+00,\n",
       "           2.85000000e+01,   9.20000000e+01,   2.13000000e+00,\n",
       "           2.24000000e+00,   5.80000000e-01,   1.76000000e+00,\n",
       "           3.00000000e+00,   9.70000000e-01,   2.44000000e+00,\n",
       "           4.66000000e+02],\n",
       "        [  1.23700000e+01,   9.40000000e-01,   1.36000000e+00,\n",
       "           1.06000000e+01,   8.80000000e+01,   1.98000000e+00,\n",
       "           5.70000000e-01,   2.80000000e-01,   4.20000000e-01,\n",
       "           1.95000000e+00,   1.05000000e+00,   1.82000000e+00,\n",
       "           5.20000000e+02],\n",
       "        [  1.43000000e+01,   1.92000000e+00,   2.72000000e+00,\n",
       "           2.00000000e+01,   1.20000000e+02,   2.80000000e+00,\n",
       "           3.14000000e+00,   3.30000000e-01,   1.97000000e+00,\n",
       "           6.20000000e+00,   1.07000000e+00,   2.65000000e+00,\n",
       "           1.28000000e+03],\n",
       "        [  1.29300000e+01,   3.80000000e+00,   2.65000000e+00,\n",
       "           1.86000000e+01,   1.02000000e+02,   2.41000000e+00,\n",
       "           2.41000000e+00,   2.50000000e-01,   1.98000000e+00,\n",
       "           4.50000000e+00,   1.03000000e+00,   3.52000000e+00,\n",
       "           7.70000000e+02],\n",
       "        [  1.30500000e+01,   1.77000000e+00,   2.10000000e+00,\n",
       "           1.70000000e+01,   1.07000000e+02,   3.00000000e+00,\n",
       "           3.00000000e+00,   2.80000000e-01,   2.03000000e+00,\n",
       "           5.04000000e+00,   8.80000000e-01,   3.35000000e+00,\n",
       "           8.85000000e+02],\n",
       "        [  1.37500000e+01,   1.73000000e+00,   2.41000000e+00,\n",
       "           1.60000000e+01,   8.90000000e+01,   2.60000000e+00,\n",
       "           2.76000000e+00,   2.90000000e-01,   1.81000000e+00,\n",
       "           5.60000000e+00,   1.15000000e+00,   2.90000000e+00,\n",
       "           1.32000000e+03],\n",
       "        [  1.35800000e+01,   2.58000000e+00,   2.69000000e+00,\n",
       "           2.45000000e+01,   1.05000000e+02,   1.55000000e+00,\n",
       "           8.40000000e-01,   3.90000000e-01,   1.54000000e+00,\n",
       "           8.66000000e+00,   7.40000000e-01,   1.80000000e+00,\n",
       "           7.50000000e+02],\n",
       "        [  1.20000000e+01,   1.51000000e+00,   2.42000000e+00,\n",
       "           2.20000000e+01,   8.60000000e+01,   1.45000000e+00,\n",
       "           1.25000000e+00,   5.00000000e-01,   1.63000000e+00,\n",
       "           3.60000000e+00,   1.05000000e+00,   2.65000000e+00,\n",
       "           4.50000000e+02],\n",
       "        [  1.22500000e+01,   1.73000000e+00,   2.12000000e+00,\n",
       "           1.90000000e+01,   8.00000000e+01,   1.65000000e+00,\n",
       "           2.03000000e+00,   3.70000000e-01,   1.63000000e+00,\n",
       "           3.40000000e+00,   1.00000000e+00,   3.17000000e+00,\n",
       "           5.10000000e+02],\n",
       "        [  1.35100000e+01,   1.80000000e+00,   2.65000000e+00,\n",
       "           1.90000000e+01,   1.10000000e+02,   2.35000000e+00,\n",
       "           2.53000000e+00,   2.90000000e-01,   1.54000000e+00,\n",
       "           4.20000000e+00,   1.10000000e+00,   2.87000000e+00,\n",
       "           1.09500000e+03],\n",
       "        [  1.27200000e+01,   1.81000000e+00,   2.20000000e+00,\n",
       "           1.88000000e+01,   8.60000000e+01,   2.20000000e+00,\n",
       "           2.53000000e+00,   2.60000000e-01,   1.77000000e+00,\n",
       "           3.90000000e+00,   1.16000000e+00,   3.14000000e+00,\n",
       "           7.14000000e+02],\n",
       "        [  1.24300000e+01,   1.53000000e+00,   2.29000000e+00,\n",
       "           2.15000000e+01,   8.60000000e+01,   2.74000000e+00,\n",
       "           3.15000000e+00,   3.90000000e-01,   1.77000000e+00,\n",
       "           3.94000000e+00,   6.90000000e-01,   2.84000000e+00,\n",
       "           3.52000000e+02],\n",
       "        [  1.25100000e+01,   1.73000000e+00,   1.98000000e+00,\n",
       "           2.05000000e+01,   8.50000000e+01,   2.20000000e+00,\n",
       "           1.92000000e+00,   3.20000000e-01,   1.48000000e+00,\n",
       "           2.94000000e+00,   1.04000000e+00,   3.57000000e+00,\n",
       "           6.72000000e+02],\n",
       "        [  1.43700000e+01,   1.95000000e+00,   2.50000000e+00,\n",
       "           1.68000000e+01,   1.13000000e+02,   3.85000000e+00,\n",
       "           3.49000000e+00,   2.40000000e-01,   2.18000000e+00,\n",
       "           7.80000000e+00,   8.60000000e-01,   3.45000000e+00,\n",
       "           1.48000000e+03],\n",
       "        [  1.24700000e+01,   1.52000000e+00,   2.20000000e+00,\n",
       "           1.90000000e+01,   1.62000000e+02,   2.50000000e+00,\n",
       "           2.27000000e+00,   3.20000000e-01,   3.28000000e+00,\n",
       "           2.60000000e+00,   1.16000000e+00,   2.63000000e+00,\n",
       "           9.37000000e+02],\n",
       "        [  1.30700000e+01,   1.50000000e+00,   2.10000000e+00,\n",
       "           1.55000000e+01,   9.80000000e+01,   2.40000000e+00,\n",
       "           2.64000000e+00,   2.80000000e-01,   1.37000000e+00,\n",
       "           3.70000000e+00,   1.18000000e+00,   2.69000000e+00,\n",
       "           1.02000000e+03],\n",
       "        [  1.33000000e+01,   1.72000000e+00,   2.14000000e+00,\n",
       "           1.70000000e+01,   9.40000000e+01,   2.40000000e+00,\n",
       "           2.19000000e+00,   2.70000000e-01,   1.35000000e+00,\n",
       "           3.95000000e+00,   1.02000000e+00,   2.77000000e+00,\n",
       "           1.28500000e+03],\n",
       "        [  1.27700000e+01,   3.43000000e+00,   1.98000000e+00,\n",
       "           1.60000000e+01,   8.00000000e+01,   1.63000000e+00,\n",
       "           1.25000000e+00,   4.30000000e-01,   8.30000000e-01,\n",
       "           3.40000000e+00,   7.00000000e-01,   2.12000000e+00,\n",
       "           3.72000000e+02],\n",
       "        [  1.42200000e+01,   3.99000000e+00,   2.51000000e+00,\n",
       "           1.32000000e+01,   1.28000000e+02,   3.00000000e+00,\n",
       "           3.04000000e+00,   2.00000000e-01,   2.08000000e+00,\n",
       "           5.10000000e+00,   8.90000000e-01,   3.53000000e+00,\n",
       "           7.60000000e+02],\n",
       "        [  1.27200000e+01,   1.75000000e+00,   2.28000000e+00,\n",
       "           2.25000000e+01,   8.40000000e+01,   1.38000000e+00,\n",
       "           1.76000000e+00,   4.80000000e-01,   1.63000000e+00,\n",
       "           3.30000000e+00,   8.80000000e-01,   2.42000000e+00,\n",
       "           4.88000000e+02],\n",
       "        [  1.27000000e+01,   3.87000000e+00,   2.40000000e+00,\n",
       "           2.30000000e+01,   1.01000000e+02,   2.83000000e+00,\n",
       "           2.55000000e+00,   4.30000000e-01,   1.95000000e+00,\n",
       "           2.57000000e+00,   1.19000000e+00,   3.13000000e+00,\n",
       "           4.63000000e+02],\n",
       "        [  1.30500000e+01,   1.73000000e+00,   2.04000000e+00,\n",
       "           1.24000000e+01,   9.20000000e+01,   2.72000000e+00,\n",
       "           3.27000000e+00,   1.70000000e-01,   2.91000000e+00,\n",
       "           7.20000000e+00,   1.12000000e+00,   2.91000000e+00,\n",
       "           1.15000000e+03],\n",
       "        [  1.20800000e+01,   1.83000000e+00,   2.32000000e+00,\n",
       "           1.85000000e+01,   8.10000000e+01,   1.60000000e+00,\n",
       "           1.50000000e+00,   5.20000000e-01,   1.64000000e+00,\n",
       "           2.40000000e+00,   1.08000000e+00,   2.27000000e+00,\n",
       "           4.80000000e+02],\n",
       "        [  1.37100000e+01,   5.65000000e+00,   2.45000000e+00,\n",
       "           2.05000000e+01,   9.50000000e+01,   1.68000000e+00,\n",
       "           6.10000000e-01,   5.20000000e-01,   1.06000000e+00,\n",
       "           7.70000000e+00,   6.40000000e-01,   1.74000000e+00,\n",
       "           7.40000000e+02],\n",
       "        [  1.31700000e+01,   2.59000000e+00,   2.37000000e+00,\n",
       "           2.00000000e+01,   1.20000000e+02,   1.65000000e+00,\n",
       "           6.80000000e-01,   5.30000000e-01,   1.46000000e+00,\n",
       "           9.30000000e+00,   6.00000000e-01,   1.62000000e+00,\n",
       "           8.40000000e+02],\n",
       "        [  1.33600000e+01,   2.56000000e+00,   2.35000000e+00,\n",
       "           2.00000000e+01,   8.90000000e+01,   1.40000000e+00,\n",
       "           5.00000000e-01,   3.70000000e-01,   6.40000000e-01,\n",
       "           5.60000000e+00,   7.00000000e-01,   2.47000000e+00,\n",
       "           7.80000000e+02],\n",
       "        [  1.37600000e+01,   1.53000000e+00,   2.70000000e+00,\n",
       "           1.95000000e+01,   1.32000000e+02,   2.95000000e+00,\n",
       "           2.74000000e+00,   5.00000000e-01,   1.35000000e+00,\n",
       "           5.40000000e+00,   1.25000000e+00,   3.00000000e+00,\n",
       "           1.23500000e+03]]),\n",
       " array([2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 0, 2, 2, 1, 1, 2,\n",
       "        2, 1, 0, 1, 2, 0, 2, 0, 0, 1, 1, 2, 1, 1, 2, 2, 0, 2, 2, 0, 2, 2, 1,\n",
       "        0, 1, 2, 2, 0, 1, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 2, 0, 0, 2, 1, 1, 1,\n",
       "        0, 2, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 0, 2, 1, 1, 1, 1,\n",
       "        2, 1, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 2, 1, 0, 1, 0, 2,\n",
       "        2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 0, 1, 1]),\n",
       " array([2, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 2, 2, 2, 0])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(feat_data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(feat_data,labels,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_x_test = scaler.transform(x_test) #don't fit since we don't know what the test data will be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers API Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot_y_train = pd.get_dummies(y_train).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot_y_test = pd.get_dummies(y_test).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_feat = 13\n",
    "num_hidden1 = 13 #number of neurons in first hidden layer\n",
    "num_hidden2 = 13\n",
    "num_outputs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,num_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape=[None,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actf = tf.nn.relu #activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden1 = fully_connected(x,num_hidden1,activation_fn=actf) # \"layers\" API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden2 = fully_connected(hidden1,num_hidden2,activation_fn=actf) # \"layers\" API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = fully_connected(hidden2,num_outputs) # \"layers\" API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=y_true,logits=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(training_steps):\n",
    "        sess.run(train,feed_dict={x:scaled_x_train,y_true:onehot_y_train})\n",
    "        \n",
    "    logits = output.eval(feed_dict={x:scaled_x_test})\n",
    "    preds = tf.argmax(logits,axis=1)\n",
    "    results = preds.eval()\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      1.00      1.00        22\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
