{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Data Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- 1) Alcohol\n",
      " \t\t- 2) Malic acid\n",
      " \t\t- 3) Ash\n",
      "\t\t- 4) Alcalinity of ash  \n",
      " \t\t- 5) Magnesium\n",
      "\t\t- 6) Total phenols\n",
      " \t\t- 7) Flavanoids\n",
      " \t\t- 8) Nonflavanoid phenols\n",
      " \t\t- 9) Proanthocyanins\n",
      "\t\t- 10)Color intensity\n",
      " \t\t- 11)Hue\n",
      " \t\t- 12)OD280/OD315 of diluted wines\n",
      " \t\t- 13)Proline\n",
      "        \t- class:\n",
      "                - class_0\n",
      "                - class_1\n",
      "                - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      "References\n",
      "----------\n",
      "(1) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "Comparison of Classifiers in High Dimensional Settings, \n",
      "Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Technometrics). \n",
      "\n",
      "The data was used with many others for comparing various \n",
      "classifiers. The classes are separable, though only RDA \n",
      "has achieved 100% correct classification. \n",
      "(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "(All results using the leave-one-out technique) \n",
      "\n",
      "(2) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "\"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Journal of Chemometrics). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine_data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_data = wine_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.42300000e+01,   1.71000000e+00,   2.43000000e+00, ...,\n",
       "          1.04000000e+00,   3.92000000e+00,   1.06500000e+03],\n",
       "       [  1.32000000e+01,   1.78000000e+00,   2.14000000e+00, ...,\n",
       "          1.05000000e+00,   3.40000000e+00,   1.05000000e+03],\n",
       "       [  1.31600000e+01,   2.36000000e+00,   2.67000000e+00, ...,\n",
       "          1.03000000e+00,   3.17000000e+00,   1.18500000e+03],\n",
       "       ..., \n",
       "       [  1.32700000e+01,   4.28000000e+00,   2.26000000e+00, ...,\n",
       "          5.90000000e-01,   1.56000000e+00,   8.35000000e+02],\n",
       "       [  1.31700000e+01,   2.59000000e+00,   2.37000000e+00, ...,\n",
       "          6.00000000e-01,   1.62000000e+00,   8.40000000e+02],\n",
       "       [  1.41300000e+01,   4.10000000e+00,   2.74000000e+00, ...,\n",
       "          6.10000000e-01,   1.60000000e+00,   5.60000000e+02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = wine_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  1.33900000e+01,   1.77000000e+00,   2.62000000e+00, ...,\n",
       "           9.20000000e-01,   3.22000000e+00,   1.19500000e+03],\n",
       "        [  1.37300000e+01,   1.50000000e+00,   2.70000000e+00, ...,\n",
       "           1.19000000e+00,   2.71000000e+00,   1.28500000e+03],\n",
       "        [  1.17900000e+01,   2.13000000e+00,   2.78000000e+00, ...,\n",
       "           9.70000000e-01,   2.44000000e+00,   4.66000000e+02],\n",
       "        ..., \n",
       "        [  1.23400000e+01,   2.45000000e+00,   2.46000000e+00, ...,\n",
       "           8.00000000e-01,   3.38000000e+00,   4.38000000e+02],\n",
       "        [  1.43900000e+01,   1.87000000e+00,   2.45000000e+00, ...,\n",
       "           1.02000000e+00,   3.58000000e+00,   1.29000000e+03],\n",
       "        [  1.34800000e+01,   1.81000000e+00,   2.41000000e+00, ...,\n",
       "           1.04000000e+00,   3.47000000e+00,   9.20000000e+02]]),\n",
       " array([[  1.35000000e+01,   3.12000000e+00,   2.62000000e+00,\n",
       "           2.40000000e+01,   1.23000000e+02,   1.40000000e+00,\n",
       "           1.57000000e+00,   2.20000000e-01,   1.25000000e+00,\n",
       "           8.60000000e+00,   5.90000000e-01,   1.30000000e+00,\n",
       "           5.00000000e+02],\n",
       "        [  1.17600000e+01,   2.68000000e+00,   2.92000000e+00,\n",
       "           2.00000000e+01,   1.03000000e+02,   1.75000000e+00,\n",
       "           2.03000000e+00,   6.00000000e-01,   1.05000000e+00,\n",
       "           3.80000000e+00,   1.23000000e+00,   2.50000000e+00,\n",
       "           6.07000000e+02],\n",
       "        [  1.16400000e+01,   2.06000000e+00,   2.46000000e+00,\n",
       "           2.16000000e+01,   8.40000000e+01,   1.95000000e+00,\n",
       "           1.69000000e+00,   4.80000000e-01,   1.35000000e+00,\n",
       "           2.80000000e+00,   1.00000000e+00,   2.75000000e+00,\n",
       "           6.80000000e+02],\n",
       "        [  1.20800000e+01,   1.83000000e+00,   2.32000000e+00,\n",
       "           1.85000000e+01,   8.10000000e+01,   1.60000000e+00,\n",
       "           1.50000000e+00,   5.20000000e-01,   1.64000000e+00,\n",
       "           2.40000000e+00,   1.08000000e+00,   2.27000000e+00,\n",
       "           4.80000000e+02],\n",
       "        [  1.27200000e+01,   1.75000000e+00,   2.28000000e+00,\n",
       "           2.25000000e+01,   8.40000000e+01,   1.38000000e+00,\n",
       "           1.76000000e+00,   4.80000000e-01,   1.63000000e+00,\n",
       "           3.30000000e+00,   8.80000000e-01,   2.42000000e+00,\n",
       "           4.88000000e+02],\n",
       "        [  1.31700000e+01,   2.59000000e+00,   2.37000000e+00,\n",
       "           2.00000000e+01,   1.20000000e+02,   1.65000000e+00,\n",
       "           6.80000000e-01,   5.30000000e-01,   1.46000000e+00,\n",
       "           9.30000000e+00,   6.00000000e-01,   1.62000000e+00,\n",
       "           8.40000000e+02],\n",
       "        [  1.36400000e+01,   3.10000000e+00,   2.56000000e+00,\n",
       "           1.52000000e+01,   1.16000000e+02,   2.70000000e+00,\n",
       "           3.03000000e+00,   1.70000000e-01,   1.66000000e+00,\n",
       "           5.10000000e+00,   9.60000000e-01,   3.36000000e+00,\n",
       "           8.45000000e+02],\n",
       "        [  1.34900000e+01,   3.59000000e+00,   2.19000000e+00,\n",
       "           1.95000000e+01,   8.80000000e+01,   1.62000000e+00,\n",
       "           4.80000000e-01,   5.80000000e-01,   8.80000000e-01,\n",
       "           5.70000000e+00,   8.10000000e-01,   1.82000000e+00,\n",
       "           5.80000000e+02],\n",
       "        [  1.41600000e+01,   2.51000000e+00,   2.48000000e+00,\n",
       "           2.00000000e+01,   9.10000000e+01,   1.68000000e+00,\n",
       "           7.00000000e-01,   4.40000000e-01,   1.24000000e+00,\n",
       "           9.70000000e+00,   6.20000000e-01,   1.71000000e+00,\n",
       "           6.60000000e+02],\n",
       "        [  1.33200000e+01,   3.24000000e+00,   2.38000000e+00,\n",
       "           2.15000000e+01,   9.20000000e+01,   1.93000000e+00,\n",
       "           7.60000000e-01,   4.50000000e-01,   1.25000000e+00,\n",
       "           8.42000000e+00,   5.50000000e-01,   1.62000000e+00,\n",
       "           6.50000000e+02],\n",
       "        [  1.41000000e+01,   2.02000000e+00,   2.40000000e+00,\n",
       "           1.88000000e+01,   1.03000000e+02,   2.75000000e+00,\n",
       "           2.92000000e+00,   3.20000000e-01,   2.38000000e+00,\n",
       "           6.20000000e+00,   1.07000000e+00,   2.75000000e+00,\n",
       "           1.06000000e+03],\n",
       "        [  1.34100000e+01,   3.84000000e+00,   2.12000000e+00,\n",
       "           1.88000000e+01,   9.00000000e+01,   2.45000000e+00,\n",
       "           2.68000000e+00,   2.70000000e-01,   1.48000000e+00,\n",
       "           4.28000000e+00,   9.10000000e-01,   3.00000000e+00,\n",
       "           1.03500000e+03],\n",
       "        [  1.35000000e+01,   1.81000000e+00,   2.61000000e+00,\n",
       "           2.00000000e+01,   9.60000000e+01,   2.53000000e+00,\n",
       "           2.61000000e+00,   2.80000000e-01,   1.66000000e+00,\n",
       "           3.52000000e+00,   1.12000000e+00,   3.82000000e+00,\n",
       "           8.45000000e+02],\n",
       "        [  1.22900000e+01,   3.17000000e+00,   2.21000000e+00,\n",
       "           1.80000000e+01,   8.80000000e+01,   2.85000000e+00,\n",
       "           2.99000000e+00,   4.50000000e-01,   2.81000000e+00,\n",
       "           2.30000000e+00,   1.42000000e+00,   2.83000000e+00,\n",
       "           4.06000000e+02],\n",
       "        [  1.41300000e+01,   4.10000000e+00,   2.74000000e+00,\n",
       "           2.45000000e+01,   9.60000000e+01,   2.05000000e+00,\n",
       "           7.60000000e-01,   5.60000000e-01,   1.35000000e+00,\n",
       "           9.20000000e+00,   6.10000000e-01,   1.60000000e+00,\n",
       "           5.60000000e+02],\n",
       "        [  1.43400000e+01,   1.68000000e+00,   2.70000000e+00,\n",
       "           2.50000000e+01,   9.80000000e+01,   2.80000000e+00,\n",
       "           1.31000000e+00,   5.30000000e-01,   2.70000000e+00,\n",
       "           1.30000000e+01,   5.70000000e-01,   1.96000000e+00,\n",
       "           6.60000000e+02],\n",
       "        [  1.22500000e+01,   3.88000000e+00,   2.20000000e+00,\n",
       "           1.85000000e+01,   1.12000000e+02,   1.38000000e+00,\n",
       "           7.80000000e-01,   2.90000000e-01,   1.14000000e+00,\n",
       "           8.21000000e+00,   6.50000000e-01,   2.00000000e+00,\n",
       "           8.55000000e+02],\n",
       "        [  1.34000000e+01,   3.91000000e+00,   2.48000000e+00,\n",
       "           2.30000000e+01,   1.02000000e+02,   1.80000000e+00,\n",
       "           7.50000000e-01,   4.30000000e-01,   1.41000000e+00,\n",
       "           7.30000000e+00,   7.00000000e-01,   1.56000000e+00,\n",
       "           7.50000000e+02],\n",
       "        [  1.16500000e+01,   1.67000000e+00,   2.62000000e+00,\n",
       "           2.60000000e+01,   8.80000000e+01,   1.92000000e+00,\n",
       "           1.61000000e+00,   4.00000000e-01,   1.34000000e+00,\n",
       "           2.60000000e+00,   1.36000000e+00,   3.21000000e+00,\n",
       "           5.62000000e+02],\n",
       "        [  1.32000000e+01,   1.78000000e+00,   2.14000000e+00,\n",
       "           1.12000000e+01,   1.00000000e+02,   2.65000000e+00,\n",
       "           2.76000000e+00,   2.60000000e-01,   1.28000000e+00,\n",
       "           4.38000000e+00,   1.05000000e+00,   3.40000000e+00,\n",
       "           1.05000000e+03],\n",
       "        [  1.18200000e+01,   1.72000000e+00,   1.88000000e+00,\n",
       "           1.95000000e+01,   8.60000000e+01,   2.50000000e+00,\n",
       "           1.64000000e+00,   3.70000000e-01,   1.42000000e+00,\n",
       "           2.06000000e+00,   9.40000000e-01,   2.44000000e+00,\n",
       "           4.15000000e+02],\n",
       "        [  1.14100000e+01,   7.40000000e-01,   2.50000000e+00,\n",
       "           2.10000000e+01,   8.80000000e+01,   2.48000000e+00,\n",
       "           2.01000000e+00,   4.20000000e-01,   1.44000000e+00,\n",
       "           3.08000000e+00,   1.10000000e+00,   2.31000000e+00,\n",
       "           4.34000000e+02],\n",
       "        [  1.27700000e+01,   2.39000000e+00,   2.28000000e+00,\n",
       "           1.95000000e+01,   8.60000000e+01,   1.39000000e+00,\n",
       "           5.10000000e-01,   4.80000000e-01,   6.40000000e-01,\n",
       "           9.89999900e+00,   5.70000000e-01,   1.63000000e+00,\n",
       "           4.70000000e+02],\n",
       "        [  1.31700000e+01,   5.19000000e+00,   2.32000000e+00,\n",
       "           2.20000000e+01,   9.30000000e+01,   1.74000000e+00,\n",
       "           6.30000000e-01,   6.10000000e-01,   1.55000000e+00,\n",
       "           7.90000000e+00,   6.00000000e-01,   1.48000000e+00,\n",
       "           7.25000000e+02],\n",
       "        [  1.18200000e+01,   1.47000000e+00,   1.99000000e+00,\n",
       "           2.08000000e+01,   8.60000000e+01,   1.98000000e+00,\n",
       "           1.60000000e+00,   3.00000000e-01,   1.53000000e+00,\n",
       "           1.95000000e+00,   9.50000000e-01,   3.33000000e+00,\n",
       "           4.95000000e+02],\n",
       "        [  1.24200000e+01,   1.61000000e+00,   2.19000000e+00,\n",
       "           2.25000000e+01,   1.08000000e+02,   2.00000000e+00,\n",
       "           2.09000000e+00,   3.40000000e-01,   1.61000000e+00,\n",
       "           2.06000000e+00,   1.06000000e+00,   2.96000000e+00,\n",
       "           3.45000000e+02],\n",
       "        [  1.43800000e+01,   3.59000000e+00,   2.28000000e+00,\n",
       "           1.60000000e+01,   1.02000000e+02,   3.25000000e+00,\n",
       "           3.17000000e+00,   2.70000000e-01,   2.19000000e+00,\n",
       "           4.90000000e+00,   1.04000000e+00,   3.44000000e+00,\n",
       "           1.06500000e+03],\n",
       "        [  1.23700000e+01,   1.21000000e+00,   2.56000000e+00,\n",
       "           1.81000000e+01,   9.80000000e+01,   2.42000000e+00,\n",
       "           2.65000000e+00,   3.70000000e-01,   2.08000000e+00,\n",
       "           4.60000000e+00,   1.19000000e+00,   2.30000000e+00,\n",
       "           6.78000000e+02],\n",
       "        [  1.38600000e+01,   1.35000000e+00,   2.27000000e+00,\n",
       "           1.60000000e+01,   9.80000000e+01,   2.98000000e+00,\n",
       "           3.15000000e+00,   2.20000000e-01,   1.85000000e+00,\n",
       "           7.22000000e+00,   1.01000000e+00,   3.55000000e+00,\n",
       "           1.04500000e+03],\n",
       "        [  1.29300000e+01,   2.81000000e+00,   2.70000000e+00,\n",
       "           2.10000000e+01,   9.60000000e+01,   1.54000000e+00,\n",
       "           5.00000000e-01,   5.30000000e-01,   7.50000000e-01,\n",
       "           4.60000000e+00,   7.70000000e-01,   2.31000000e+00,\n",
       "           6.00000000e+02],\n",
       "        [  1.35800000e+01,   1.66000000e+00,   2.36000000e+00,\n",
       "           1.91000000e+01,   1.06000000e+02,   2.86000000e+00,\n",
       "           3.19000000e+00,   2.20000000e-01,   1.95000000e+00,\n",
       "           6.90000000e+00,   1.09000000e+00,   2.88000000e+00,\n",
       "           1.51500000e+03],\n",
       "        [  1.37800000e+01,   2.76000000e+00,   2.30000000e+00,\n",
       "           2.20000000e+01,   9.00000000e+01,   1.35000000e+00,\n",
       "           6.80000000e-01,   4.10000000e-01,   1.03000000e+00,\n",
       "           9.58000000e+00,   7.00000000e-01,   1.68000000e+00,\n",
       "           6.15000000e+02],\n",
       "        [  1.20800000e+01,   1.13000000e+00,   2.51000000e+00,\n",
       "           2.40000000e+01,   7.80000000e+01,   2.00000000e+00,\n",
       "           1.58000000e+00,   4.00000000e-01,   1.40000000e+00,\n",
       "           2.20000000e+00,   1.31000000e+00,   2.72000000e+00,\n",
       "           6.30000000e+02],\n",
       "        [  1.40600000e+01,   1.63000000e+00,   2.28000000e+00,\n",
       "           1.60000000e+01,   1.26000000e+02,   3.00000000e+00,\n",
       "           3.17000000e+00,   2.40000000e-01,   2.10000000e+00,\n",
       "           5.65000000e+00,   1.09000000e+00,   3.71000000e+00,\n",
       "           7.80000000e+02],\n",
       "        [  1.32800000e+01,   1.64000000e+00,   2.84000000e+00,\n",
       "           1.55000000e+01,   1.10000000e+02,   2.60000000e+00,\n",
       "           2.68000000e+00,   3.40000000e-01,   1.36000000e+00,\n",
       "           4.60000000e+00,   1.09000000e+00,   2.78000000e+00,\n",
       "           8.80000000e+02],\n",
       "        [  1.37100000e+01,   5.65000000e+00,   2.45000000e+00,\n",
       "           2.05000000e+01,   9.50000000e+01,   1.68000000e+00,\n",
       "           6.10000000e-01,   5.20000000e-01,   1.06000000e+00,\n",
       "           7.70000000e+00,   6.40000000e-01,   1.74000000e+00,\n",
       "           7.40000000e+02],\n",
       "        [  1.40200000e+01,   1.68000000e+00,   2.21000000e+00,\n",
       "           1.60000000e+01,   9.60000000e+01,   2.65000000e+00,\n",
       "           2.33000000e+00,   2.60000000e-01,   1.98000000e+00,\n",
       "           4.70000000e+00,   1.04000000e+00,   3.59000000e+00,\n",
       "           1.03500000e+03],\n",
       "        [  1.22000000e+01,   3.03000000e+00,   2.32000000e+00,\n",
       "           1.90000000e+01,   9.60000000e+01,   1.25000000e+00,\n",
       "           4.90000000e-01,   4.00000000e-01,   7.30000000e-01,\n",
       "           5.50000000e+00,   6.60000000e-01,   1.83000000e+00,\n",
       "           5.10000000e+02],\n",
       "        [  1.26000000e+01,   1.34000000e+00,   1.90000000e+00,\n",
       "           1.85000000e+01,   8.80000000e+01,   1.45000000e+00,\n",
       "           1.36000000e+00,   2.90000000e-01,   1.35000000e+00,\n",
       "           2.45000000e+00,   1.04000000e+00,   2.77000000e+00,\n",
       "           5.62000000e+02],\n",
       "        [  1.14500000e+01,   2.40000000e+00,   2.42000000e+00,\n",
       "           2.00000000e+01,   9.60000000e+01,   2.90000000e+00,\n",
       "           2.79000000e+00,   3.20000000e-01,   1.83000000e+00,\n",
       "           3.25000000e+00,   8.00000000e-01,   3.39000000e+00,\n",
       "           6.25000000e+02],\n",
       "        [  1.35100000e+01,   1.80000000e+00,   2.65000000e+00,\n",
       "           1.90000000e+01,   1.10000000e+02,   2.35000000e+00,\n",
       "           2.53000000e+00,   2.90000000e-01,   1.54000000e+00,\n",
       "           4.20000000e+00,   1.10000000e+00,   2.87000000e+00,\n",
       "           1.09500000e+03],\n",
       "        [  1.22500000e+01,   4.72000000e+00,   2.54000000e+00,\n",
       "           2.10000000e+01,   8.90000000e+01,   1.38000000e+00,\n",
       "           4.70000000e-01,   5.30000000e-01,   8.00000000e-01,\n",
       "           3.85000000e+00,   7.50000000e-01,   1.27000000e+00,\n",
       "           7.20000000e+02],\n",
       "        [  1.39000000e+01,   1.68000000e+00,   2.12000000e+00,\n",
       "           1.60000000e+01,   1.01000000e+02,   3.10000000e+00,\n",
       "           3.39000000e+00,   2.10000000e-01,   2.14000000e+00,\n",
       "           6.10000000e+00,   9.10000000e-01,   3.33000000e+00,\n",
       "           9.85000000e+02],\n",
       "        [  1.27200000e+01,   1.81000000e+00,   2.20000000e+00,\n",
       "           1.88000000e+01,   8.60000000e+01,   2.20000000e+00,\n",
       "           2.53000000e+00,   2.60000000e-01,   1.77000000e+00,\n",
       "           3.90000000e+00,   1.16000000e+00,   3.14000000e+00,\n",
       "           7.14000000e+02],\n",
       "        [  1.29900000e+01,   1.67000000e+00,   2.60000000e+00,\n",
       "           3.00000000e+01,   1.39000000e+02,   3.30000000e+00,\n",
       "           2.89000000e+00,   2.10000000e-01,   1.96000000e+00,\n",
       "           3.35000000e+00,   1.31000000e+00,   3.50000000e+00,\n",
       "           9.85000000e+02]]),\n",
       " array([0, 0, 1, 0, 0, 0, 2, 1, 2, 1, 0, 1, 0, 1, 1, 2, 0, 2, 0, 1, 0, 1, 0,\n",
       "        2, 1, 0, 1, 0, 1, 0, 1, 1, 2, 1, 2, 0, 0, 1, 0, 0, 1, 0, 2, 1, 2, 1,\n",
       "        0, 1, 2, 1, 1, 0, 0, 2, 2, 1, 1, 0, 0, 0, 1, 1, 2, 2, 0, 1, 2, 2, 1,\n",
       "        2, 0, 0, 2, 0, 1, 0, 0, 1, 2, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 1, 2, 0, 1, 2, 2, 1, 0, 2, 1, 1, 0, 0, 2, 1, 1, 2, 1, 1,\n",
       "        2, 1, 2, 0, 1, 1, 2, 1, 0, 1, 2, 1, 1, 0, 2, 1, 0, 0]),\n",
       " array([2, 1, 1, 1, 1, 2, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2,\n",
       "        2, 1, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0, 2, 0, 2, 1, 1, 0, 2, 0, 1, 1])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(feat_data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(feat_data,labels,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_x_test = scaler.transform(x_test) #don't fit since we don't know what the test data will be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_keras_model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_keras_model.add(layers.Dense(units=13,input_dim=13,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_keras_model.add(layers.Dense(units=13,activation='relu'))\n",
    "dnn_keras_model.add(layers.Dense(units=13,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_keras_model.add(layers.Dense(units=3,activation='softmax')) #3 units, one for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import losses,optimizers,metrics,activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_keras_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', #sets up the layers as they should be\n",
    "                       metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 0s - loss: 1.1050 - acc: 0.2258     \n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s - loss: 1.0975 - acc: 0.3226     \n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s - loss: 1.0926 - acc: 0.3226     \n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s - loss: 1.0870 - acc: 0.3226     \n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s - loss: 1.0815 - acc: 0.3226     \n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s - loss: 1.0751 - acc: 0.3226     \n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s - loss: 1.0677 - acc: 0.3226     \n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s - loss: 1.0605 - acc: 0.3226     \n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s - loss: 1.0505 - acc: 0.3306     \n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s - loss: 1.0401 - acc: 0.3306     \n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s - loss: 1.0286 - acc: 0.3387     \n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s - loss: 1.0161 - acc: 0.3387     \n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s - loss: 1.0014 - acc: 0.3387     \n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s - loss: 0.9854 - acc: 0.3548     \n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s - loss: 0.9667 - acc: 0.3710     \n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s - loss: 0.9479 - acc: 0.3952     \n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s - loss: 0.9252 - acc: 0.4032     \n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s - loss: 0.9029 - acc: 0.4032     \n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s - loss: 0.8802 - acc: 0.4355     \n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s - loss: 0.8586 - acc: 0.4597     \n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s - loss: 0.8379 - acc: 0.5484     \n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s - loss: 0.8178 - acc: 0.6210     \n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s - loss: 0.7987 - acc: 0.6452     \n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s - loss: 0.7791 - acc: 0.6613     \n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s - loss: 0.7581 - acc: 0.7097     \n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s - loss: 0.7331 - acc: 0.7661     \n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s - loss: 0.7111 - acc: 0.8629     \n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s - loss: 0.6811 - acc: 0.8710     \n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s - loss: 0.6514 - acc: 0.8710     \n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s - loss: 0.6239 - acc: 0.8871     \n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s - loss: 0.5930 - acc: 0.9194     \n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s - loss: 0.5630 - acc: 0.9032     \n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s - loss: 0.5297 - acc: 0.9032     \n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s - loss: 0.4983 - acc: 0.8952     \n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s - loss: 0.4633 - acc: 0.9194     \n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s - loss: 0.4359 - acc: 0.9274     \n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s - loss: 0.3982 - acc: 0.9355     \n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s - loss: 0.3691 - acc: 0.9355     \n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s - loss: 0.3392 - acc: 0.9355     \n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s - loss: 0.3065 - acc: 0.9435     \n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s - loss: 0.2788 - acc: 0.9516     \n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s - loss: 0.2563 - acc: 0.9435     \n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s - loss: 0.2415 - acc: 0.9516     \n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s - loss: 0.2098 - acc: 0.9516     \n",
      "Epoch 45/50\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.2211 - acc: 0.937 - 0s - loss: 0.1921 - acc: 0.9597     \n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s - loss: 0.1727 - acc: 0.9597     \n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s - loss: 0.1601 - acc: 0.9597     \n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s - loss: 0.1453 - acc: 0.9758     \n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s - loss: 0.1320 - acc: 0.9758     \n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s - loss: 0.1263 - acc: 0.9677     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x10b28be48>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_keras_model.fit(scaled_x_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "32/54 [================>.............] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predictions = dnn_keras_model.predict_classes(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.92        18\n",
      "          1       0.91      0.87      0.89        23\n",
      "          2       0.92      0.92      0.92        13\n",
      "\n",
      "avg / total       0.91      0.91      0.91        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
